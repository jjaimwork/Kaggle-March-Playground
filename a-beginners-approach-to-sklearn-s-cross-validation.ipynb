{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is to show and test my abilities to actually create a notebook and test my skills I learned from my Data Science & ML Courses \n",
    "This notebook is for everyone to see and comment on and is a test of my skills along with some research, feel free to tell me my mistakes and what I should've done, and could do better ❤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Problem Definition\n",
    "\n",
    "> Predict target values and submit the score on Kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data\n",
    "As we could see from the data this is a classification problem, some of the columns have string values we must convert into categorical values.\n",
    "\n",
    "> For this competition, you will be predicting a binary target based on a number of feature columns given in the data. All of the feature columns, cat0 - cat18 are categorical, and the feature columns cont0 - cont10 are continuous.  \n",
    "Files  \n",
    "train.csv - the training data with the target column  \n",
    "test.csv - the test set; you will be predicting the target for each row in this file (the probability of the binary target)  \n",
    "sample_submission.csv - a sample submission file in the correct format\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T12:26:04.513337Z",
     "iopub.status.busy": "2021-07-31T12:26:04.512958Z",
     "iopub.status.idle": "2021-07-31T12:26:06.204381Z",
     "shell.execute_reply": "2021-07-31T12:26:06.203122Z",
     "shell.execute_reply.started": "2021-07-31T12:26:04.513307Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T12:26:06.206295Z",
     "iopub.status.busy": "2021-07-31T12:26:06.205975Z",
     "iopub.status.idle": "2021-07-31T12:26:11.011155Z",
     "shell.execute_reply": "2021-07-31T12:26:11.009958Z",
     "shell.execute_reply.started": "2021-07-31T12:26:06.206264Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T12:26:14.354897Z",
     "iopub.status.busy": "2021-07-31T12:26:14.354503Z",
     "iopub.status.idle": "2021-07-31T12:26:14.406153Z",
     "shell.execute_reply": "2021-07-31T12:26:14.405029Z",
     "shell.execute_reply.started": "2021-07-31T12:26:14.354863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>...</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>S</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759439</td>\n",
       "      <td>0.795549</td>\n",
       "      <td>0.681917</td>\n",
       "      <td>0.621672</td>\n",
       "      <td>0.592184</td>\n",
       "      <td>0.791921</td>\n",
       "      <td>0.815254</td>\n",
       "      <td>0.965006</td>\n",
       "      <td>0.665915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>K</td>\n",
       "      <td>W</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386385</td>\n",
       "      <td>0.541366</td>\n",
       "      <td>0.388982</td>\n",
       "      <td>0.357778</td>\n",
       "      <td>0.600044</td>\n",
       "      <td>0.408701</td>\n",
       "      <td>0.399353</td>\n",
       "      <td>0.927406</td>\n",
       "      <td>0.493729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>BM</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343255</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.793687</td>\n",
       "      <td>0.552877</td>\n",
       "      <td>0.352113</td>\n",
       "      <td>0.388835</td>\n",
       "      <td>0.412303</td>\n",
       "      <td>0.292696</td>\n",
       "      <td>0.549452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>K</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>A</td>\n",
       "      <td>Y</td>\n",
       "      <td>AD</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831147</td>\n",
       "      <td>0.807807</td>\n",
       "      <td>0.800032</td>\n",
       "      <td>0.619147</td>\n",
       "      <td>0.221789</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.633669</td>\n",
       "      <td>0.760318</td>\n",
       "      <td>0.934242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>I</td>\n",
       "      <td>G</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "      <td>BI</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>Q</td>\n",
       "      <td>...</td>\n",
       "      <td>0.338818</td>\n",
       "      <td>0.277308</td>\n",
       "      <td>0.610578</td>\n",
       "      <td>0.128291</td>\n",
       "      <td>0.578764</td>\n",
       "      <td>0.279167</td>\n",
       "      <td>0.351103</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.328960</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8  ...     cont2     cont3  \\\n",
       "0   0    A    I    A    B    B   BI    A    S    Q  ...  0.759439  0.795549   \n",
       "1   1    A    I    A    A    E   BI    K    W   AD  ...  0.386385  0.541366   \n",
       "2   2    A    K    A    A    E   BI    A    E   BM  ...  0.343255  0.616352   \n",
       "3   3    A    K    A    C    E   BI    A    Y   AD  ...  0.831147  0.807807   \n",
       "4   4    A    I    G    B    E   BI    C    G    Q  ...  0.338818  0.277308   \n",
       "\n",
       "      cont4     cont5     cont6     cont7     cont8     cont9    cont10 target  \n",
       "0  0.681917  0.621672  0.592184  0.791921  0.815254  0.965006  0.665915      0  \n",
       "1  0.388982  0.357778  0.600044  0.408701  0.399353  0.927406  0.493729      0  \n",
       "2  0.793687  0.552877  0.352113  0.388835  0.412303  0.292696  0.549452      0  \n",
       "3  0.800032  0.619147  0.221789  0.897617  0.633669  0.760318  0.934242      0  \n",
       "4  0.610578  0.128291  0.578764  0.279167  0.351103  0.357084  0.328960      1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we're going to convert the categorical values and assume they are ordinal\n",
    "\n",
    "When to use a Label Encoding vs. One Hot Encoding\n",
    "This question generally depends on your dataset and the model which you wish to apply. But still, a few points to note before choosing the right encoding technique for your model:\n",
    "\n",
    "\n",
    "> **We apply One-Hot Encoding when:**  \n",
    "◽ The categorical feature is not ordinal (like the countries above)  \n",
    "◽ The number of categorical features is less so one-hot encoding can be effectively applied  \n",
    "**We apply Label Encoding when:**  \n",
    "◽ The categorical feature is ordinal (like Jr. kg, Sr. kg, Primary school, high school)  \n",
    "◽ The number of categories is quite large as one-hot encoding can lead to high memory consumption  \n",
    "link: https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/  \n",
    "\n",
    "We are also dropping the ID column above, this should help in getting optimal results rather than having our algorithims see them as values and have them result as outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T12:38:06.581236Z",
     "iopub.status.busy": "2021-07-31T12:38:06.580778Z",
     "iopub.status.idle": "2021-07-31T12:38:10.696248Z",
     "shell.execute_reply": "2021-07-31T12:38:10.695208Z",
     "shell.execute_reply.started": "2021-07-31T12:38:06.581200Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a list and store the columns\n",
    "cat_cols = []\n",
    "for col in train_df.columns:\n",
    "    cat_cols.append(col)\n",
    "\n",
    "# use only the categorical columns    \n",
    "cat_cols = cat_cols[1:20]\n",
    "\n",
    "# setup LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# loop through the dataset's columns and transform their values into numerical values\n",
    "for col in cat_cols:\n",
    "    test_df[col] = label_encoder.fit_transform(test_df[col])\n",
    "    train_df[col] = label_encoder.fit_transform(train_df[col])\n",
    "    \n",
    "# set random seed to reproduce\n",
    "np.random.seed(42)\n",
    "\n",
    "# shuffle the dataset and drop the id column\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df = train_df.drop(columns='id', axis=1)\n",
    "test_df = test_df.drop(columns='id', axis=1)\n",
    "\n",
    "# split the data\n",
    "X = train_df.drop('target', axis=1)\n",
    "y = train_df.target\n",
    "\n",
    "# split the data into train, test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're dealing with a classification problem we're going to try three different models to try and compare before we get to the experimentation part\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T12:43:09.890963Z",
     "iopub.status.busy": "2021-07-31T12:43:09.890591Z",
     "iopub.status.idle": "2021-07-31T12:43:09.895094Z",
     "shell.execute_reply": "2021-07-31T12:43:09.894201Z",
     "shell.execute_reply.started": "2021-07-31T12:43:09.890932Z"
    }
   },
   "outputs": [],
   "source": [
    "# we're going to create a dict of the different models we're going to use\n",
    "models = {\n",
    "    'Logistic Regression' : LogisticRegression(solver='liblinear'),\n",
    "    'RandomForest' : RandomForestClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T12:43:10.189967Z",
     "iopub.status.busy": "2021-07-31T12:43:10.189594Z",
     "iopub.status.idle": "2021-07-31T12:43:10.195552Z",
     "shell.execute_reply": "2021-07-31T12:43:10.194254Z",
     "shell.execute_reply.started": "2021-07-31T12:43:10.189930Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a function where we loop through the dict and use score them\n",
    "def fit_and_score(models, X_train, X_test, y_train, y_test):\n",
    "    model_scores = {}\n",
    "    for name, model in models.items(): \n",
    "        model.fit(X_train, y_train)\n",
    "        model_scores[name] = model.score(X_test, y_test)\n",
    "    return model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T12:45:42.941744Z",
     "iopub.status.busy": "2021-07-31T12:45:42.941405Z",
     "iopub.status.idle": "2021-07-31T12:48:16.716562Z",
     "shell.execute_reply": "2021-07-31T12:48:16.715458Z",
     "shell.execute_reply.started": "2021-07-31T12:45:42.941713Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.8376222222222223,\n",
       " 'RandomForest': 0.8464,\n",
       " 'KNN': 0.8109222222222222}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores = fit_and_score(models=models, X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the score above we're going to use RandomForestClassifier, unless we have a lot of time to actually test out and experiment on these algorithms having the highest one would be time efficient(unless we have a good cpu). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We're then going to manually test out hyperparameters\n",
    "this is the part where we're going to experiment a lot on, set yourself a limit on the result you want or you'll never stop training, with this amount of dataset and amount of combinations and fine-tuning your hyperparameter may take you a lot of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the meaning of these hyperparameters, go to sklearn's documentation page for more information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T06:48:13.271359Z",
     "iopub.status.busy": "2021-07-27T06:48:13.270871Z",
     "iopub.status.idle": "2021-07-27T06:48:13.278154Z",
     "shell.execute_reply": "2021-07-27T06:48:13.276809Z",
     "shell.execute_reply.started": "2021-07-27T06:48:13.271317Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_grid = {\n",
    "    'n_estimators' : np.arange(600, 1500, 50),\n",
    "    'max_depth' : [None, 1,3,5],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_split' : np.arange(1,15,1),\n",
    "    'min_samples_leaf' : np.arange(1,15,1),\n",
    "    'bootstrap' : [True ,False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it is way better to train on your own PC/locally since you can maximize the amount of threads you have especially if you have a mid-end PC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-27T06:48:22.232596Z",
     "iopub.status.busy": "2021-07-27T06:48:22.232137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  25 | elapsed: 21.9min remaining: 14.6min\n",
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed: 24.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=5,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [None, 1, 3, 5],\n",
       "                                        'max_features': ['auto'],\n",
       "                                        'min_samples_leaf': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'min_samples_split': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14]),\n",
       "                                        'n_estimators': array([ 600,  650,  700,  750,  800,  850,  900,  950, 1000, 1050, 1100,\n",
       "       1150, 1200, 1250, 1300, 1350, 1400, 1450])},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                          param_distributions=rf_grid,\n",
    "                          cv=5,\n",
    "                          n_iter=5,\n",
    "                          verbose=2,\n",
    "                          n_jobs=-1\n",
    "                          )\n",
    "rs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-31T12:58:21.923632Z",
     "iopub.status.busy": "2021-07-31T12:58:21.923278Z",
     "iopub.status.idle": "2021-07-31T12:58:21.927158Z",
     "shell.execute_reply": "2021-07-31T12:58:21.926434Z",
     "shell.execute_reply.started": "2021-07-31T12:58:21.923602Z"
    }
   },
   "source": [
    "#### now to check on the best parameters our RandomizedSearchCV has found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1200,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 10,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': None,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88822\n"
     ]
    }
   ],
   "source": [
    "rs_y_preds_proba = rs_rf.predict_proba(X_test)[:,1]\n",
    "score = roc_auc_score(y_test, rs_y_preds_proba)\n",
    "print(f'{score:0.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We then store our result to a file using pickle just incase something happens(I do this since my electricity goes out a lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pickle\n",
    "load_pickle_model = pickle.load(open('rs_random_forest_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We then use our saved model to predict on the test dataset we were given, and then save it, and then we submit our results to the kaggle page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_y_preds = load_pickle_model.predict_proba(test_df)[:,1]\n",
    "submission_df['target'] = pickle_y_preds\n",
    "submission_df.to_csv('random_forest_rs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now if we wanna go a bit further and fine-tune our model, we can use GridSearchCV\n",
    "GridSearchCV actually takes time since it doesn't randomly choose a model and skip it  \n",
    "but instead it actually tries every combination you have on your parameters dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_grid = {\n",
    "    'n_estimators' : np.arange(1100, 1350, 50),\n",
    "    'max_depth' : [None],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_split' : np.arange(8,10,1),\n",
    "    'min_samples_leaf' : np.arange(12,14,1),\n",
    "    'bootstrap' : [False]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Do Note: I got these values are from the RandomizedSearchCV best params and created a range of values to find a somewhat sweetspot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 38.5min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 169.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [False], 'max_depth': [None],\n",
       "                         'max_features': ['auto'],\n",
       "                         'min_samples_leaf': array([12, 13]),\n",
       "                         'min_samples_split': array([8, 9]),\n",
       "                         'n_estimators': array([1100, 1150, 1200, 1250, 1300])},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf = GridSearchCV(RandomForestClassifier(),\n",
    "                          param_grid=gs_grid,\n",
    "                          cv=5,\n",
    "                          verbose=2,\n",
    "                          n_jobs=-1\n",
    "                          )\n",
    "gs_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle\n",
    "pickle.dump(gs_rf, open('gs_random_forest_model.pkl', 'wb'))\n",
    "# load pickle\n",
    "load_pickle_model_gs = pickle.load(open('gs_random_forest_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 12,\n",
       " 'min_samples_split': 8,\n",
       " 'n_estimators': 1200}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_pickle_model_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.88822\n"
     ]
    }
   ],
   "source": [
    "gs_y_preds_proba = load_pickle_model_gs.predict_proba(X_test)[:,1]\n",
    "score = roc_auc_score(y_test, gs_y_preds_proba)\n",
    "print(f'{score:0.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_y_preds_gs = load_pickle_model_gs.predict_proba(test_df)[:,1]\n",
    "submission_df['target'] = pickle_y_preds_gs\n",
    "submission_df.to_csv('random_forest_gs.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special Thanks to \n",
    "\n",
    "https://www.kaggle.com/inversion/get-started-mar-tabular-playground-competition"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
